{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408764d7-ca06-4613-8f8d-0a3e709b3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c00215-bb91-4b3b-82d1-10d8bbf9fe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccfef061-754c-4f2e-b866-bb94e049aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19c4f832-d8cd-4093-87c5-e8f63e200f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2093f2-2623-4b9c-a386-cedfdcb07320",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6402b5f4-7950-4e52-bb38-5e39a04d4a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = Planetoid('/tmp/cora', 'cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce8ef461-23b2-4e9e-934e-bf58db9f9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_data = cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70452dae-8617-4052-b4eb-a0cddefe1965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora has 2708 nodes\n",
      "cora has 10556 edges\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "num_nodes = cora_data.num_nodes\n",
    "print('cora has {} nodes'.format(num_nodes))\n",
    "\n",
    "num_edges = cora_data.num_edges\n",
    "print('cora has {} edges'.format(num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb576725-b042-42b3-845d-8fe7d8f5dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "869254d3-96e1-4b6d-8571-405bf118871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in cora train set, 140\n",
      "number of nodes in cora val set, 500\n",
      "number of nodes in cora test set, 1000\n"
     ]
    }
   ],
   "source": [
    "cora_x_train = cora_data.x[cora_data.train_mask]\n",
    "cora_x_val = cora_data.x[cora_data.val_mask]\n",
    "cora_x_test = cora_data.x[cora_data.test_mask]\n",
    "\n",
    "print(\"number of nodes in cora train set,\", cora_x_train.shape[0])\n",
    "print(\"number of nodes in cora val set,\", cora_x_val.shape[0])\n",
    "print(\"number of nodes in cora test set,\", cora_x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea496a38-9639-4257-8bed-ff575ef9fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "torch.Size([2708])\n",
      "{0, 1, 2, 3, 4, 5, 6}\n",
      "[351. 217. 418. 818. 426. 298. 180.]\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data.y)\n",
    "print(cora_data.y.shape)\n",
    "s = set()\n",
    "histogram = np.zeros(7)\n",
    "for label in cora_data.y:\n",
    "    s.add(label.item())\n",
    "    histogram[label.item()]+=1\n",
    "print(s)\n",
    "print(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f19a0de-496c-4467-9890-bbe189b15d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "1433\n",
      "2708\n",
      "1\n",
      "<class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data.x.shape)\n",
    "print(cora_data.x[170:180])\n",
    "print(cora_data.num_features)\n",
    "print(cora_data.num_nodes)\n",
    "print(cora_data.num_node_types)\n",
    "print(type(cora_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e11b8540-03ea-4238-bf4a-b6a384427d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    # hidden channels will be the embedding dimension for each attention head\n",
    "    # after applying the first GAT layer.\n",
    "    def __init__(self, in_channels, hidden_channels, \n",
    "                 num_heads, dropout_rate, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, \n",
    "                                dropout=dropout_rate)\n",
    "        self.conv2 = GATConv(hidden_channels*num_heads, num_classes, \n",
    "                                dropout=dropout_rate, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        out = self.conv1(out, edge_index)\n",
    "        assert out.shape[-1] == self.hidden_channels * self.num_heads\n",
    "        \n",
    "        out = F.elu(out)\n",
    "        out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        out = self.conv2(out, edge_index)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7b11064-b1ec-4703-a301-64c56e91496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "dropout_rate = 0.4\n",
    "emb_dim1 = 8\n",
    "lr = 0.005\n",
    "\n",
    "cora_num_classes = len(cora_data.y.unique())\n",
    "assert cora_num_classes == 7\n",
    "\n",
    "cora_model = GAT(cora_data.num_features, emb_dim1, num_heads, dropout_rate, \n",
    "            cora_num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(cora_model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9002c7df-b429-4325-b334-6f9ae24c705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(pred[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8805834a-71ec-4e75-b4c0-e487266434ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data, test_mask):\n",
    "    accuracy_list = [0.0, 0.0]\n",
    "    # loss_list = [0.0, 0.0]\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    \n",
    "    for i, mask in enumerate([data.train_mask, test_mask]):\n",
    "        accuracy_list[i] = pred[mask].eq(data.y[mask]).float().mean().item()\n",
    "        # loss_list[i] = loss_fn(logits[mask], data.y[mask]).item()\n",
    "\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3c6dfe4-c8b7-4193-afd7-a60bdcd89ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|█▌        | 31/200 [00:00<00:01, 154.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.5795, Train Acc: 0.9286, Val Acc: 0.6640\n",
      "Epoch: 2, Loss: 1.4267, Train Acc: 0.9429, Val Acc: 0.7180\n",
      "Epoch: 3, Loss: 1.3247, Train Acc: 0.9429, Val Acc: 0.7420\n",
      "Epoch: 4, Loss: 1.1349, Train Acc: 0.9500, Val Acc: 0.7660\n",
      "Epoch: 5, Loss: 0.9936, Train Acc: 0.9643, Val Acc: 0.7800\n",
      "Epoch: 6, Loss: 0.8978, Train Acc: 0.9714, Val Acc: 0.7880\n",
      "Epoch: 7, Loss: 0.8970, Train Acc: 0.9714, Val Acc: 0.7880\n",
      "Epoch: 8, Loss: 0.7726, Train Acc: 0.9714, Val Acc: 0.7900\n",
      "Epoch: 9, Loss: 0.6817, Train Acc: 0.9857, Val Acc: 0.7860\n",
      "Epoch: 10, Loss: 0.6420, Train Acc: 0.9929, Val Acc: 0.7860\n",
      "Epoch: 11, Loss: 0.6064, Train Acc: 0.9929, Val Acc: 0.7820\n",
      "Epoch: 12, Loss: 0.5011, Train Acc: 0.9929, Val Acc: 0.7820\n",
      "Epoch: 13, Loss: 0.4454, Train Acc: 0.9929, Val Acc: 0.7780\n",
      "Epoch: 14, Loss: 0.4813, Train Acc: 0.9929, Val Acc: 0.7800\n",
      "Epoch: 15, Loss: 0.3980, Train Acc: 0.9929, Val Acc: 0.7760\n",
      "Epoch: 16, Loss: 0.4239, Train Acc: 0.9929, Val Acc: 0.7780\n",
      "Epoch: 17, Loss: 0.4009, Train Acc: 0.9929, Val Acc: 0.7800\n",
      "Epoch: 18, Loss: 0.3542, Train Acc: 0.9929, Val Acc: 0.7780\n",
      "Epoch: 19, Loss: 0.3090, Train Acc: 0.9929, Val Acc: 0.7740\n",
      "Epoch: 20, Loss: 0.3602, Train Acc: 0.9929, Val Acc: 0.7680\n",
      "Epoch: 21, Loss: 0.3769, Train Acc: 0.9929, Val Acc: 0.7720\n",
      "Epoch: 22, Loss: 0.3735, Train Acc: 0.9929, Val Acc: 0.7760\n",
      "Epoch: 23, Loss: 0.2643, Train Acc: 0.9929, Val Acc: 0.7780\n",
      "Epoch: 24, Loss: 0.2103, Train Acc: 0.9929, Val Acc: 0.7760\n",
      "Epoch: 25, Loss: 0.3217, Train Acc: 0.9929, Val Acc: 0.7780\n",
      "Epoch: 26, Loss: 0.3104, Train Acc: 1.0000, Val Acc: 0.7760\n",
      "Epoch: 27, Loss: 0.2447, Train Acc: 1.0000, Val Acc: 0.7760\n",
      "Epoch: 28, Loss: 0.1934, Train Acc: 1.0000, Val Acc: 0.7780\n",
      "Epoch: 29, Loss: 0.2107, Train Acc: 1.0000, Val Acc: 0.7760\n",
      "Epoch: 30, Loss: 0.1934, Train Acc: 1.0000, Val Acc: 0.7780\n",
      "Epoch: 31, Loss: 0.2684, Train Acc: 1.0000, Val Acc: 0.7780\n",
      "Epoch: 32, Loss: 0.1523, Train Acc: 1.0000, Val Acc: 0.7760\n",
      "Epoch: 33, Loss: 0.1829, Train Acc: 1.0000, Val Acc: 0.7740\n",
      "Epoch: 34, Loss: 0.2292, Train Acc: 1.0000, Val Acc: 0.7740\n",
      "Epoch: 35, Loss: 0.1849, Train Acc: 1.0000, Val Acc: 0.7740\n",
      "Epoch: 36, Loss: 0.1711, Train Acc: 1.0000, Val Acc: 0.7740\n",
      "Epoch: 37, Loss: 0.1729, Train Acc: 1.0000, Val Acc: 0.7740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  34%|███▍      | 69/200 [00:00<00:00, 177.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 0.1924, Train Acc: 1.0000, Val Acc: 0.7680\n",
      "Epoch: 39, Loss: 0.1638, Train Acc: 1.0000, Val Acc: 0.7680\n",
      "Epoch: 40, Loss: 0.1678, Train Acc: 1.0000, Val Acc: 0.7680\n",
      "Epoch: 41, Loss: 0.1536, Train Acc: 1.0000, Val Acc: 0.7660\n",
      "Epoch: 42, Loss: 0.2103, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 43, Loss: 0.1630, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 44, Loss: 0.1622, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 45, Loss: 0.1434, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 46, Loss: 0.1332, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 47, Loss: 0.1528, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 48, Loss: 0.1837, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 49, Loss: 0.1608, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 50, Loss: 0.1248, Train Acc: 1.0000, Val Acc: 0.7660\n",
      "Epoch: 51, Loss: 0.1462, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 52, Loss: 0.1173, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 53, Loss: 0.1142, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 54, Loss: 0.1638, Train Acc: 1.0000, Val Acc: 0.7600\n",
      "Epoch: 55, Loss: 0.1573, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 56, Loss: 0.1862, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 57, Loss: 0.1812, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 58, Loss: 0.1313, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 59, Loss: 0.1072, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 60, Loss: 0.1484, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 61, Loss: 0.1418, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 62, Loss: 0.1910, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 63, Loss: 0.1171, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 64, Loss: 0.1568, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 65, Loss: 0.1783, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 66, Loss: 0.1638, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 67, Loss: 0.1386, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 68, Loss: 0.0750, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 69, Loss: 0.0920, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 70, Loss: 0.0792, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 71, Loss: 0.1386, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 72, Loss: 0.1528, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 73, Loss: 0.1572, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 74, Loss: 0.1316, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 75, Loss: 0.1138, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 76, Loss: 0.1706, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 77, Loss: 0.0925, Train Acc: 1.0000, Val Acc: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  54%|█████▎    | 107/200 [00:00<00:00, 183.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Loss: 0.1749, Train Acc: 1.0000, Val Acc: 0.7600\n",
      "Epoch: 79, Loss: 0.1742, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 80, Loss: 0.2054, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 81, Loss: 0.1225, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 82, Loss: 0.1602, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 83, Loss: 0.1179, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 84, Loss: 0.1442, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 85, Loss: 0.0993, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 86, Loss: 0.1382, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 87, Loss: 0.2141, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 88, Loss: 0.1249, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 89, Loss: 0.1114, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 90, Loss: 0.1605, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 91, Loss: 0.1412, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 92, Loss: 0.1202, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 93, Loss: 0.0886, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 94, Loss: 0.0683, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 95, Loss: 0.0805, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 96, Loss: 0.0658, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 97, Loss: 0.1075, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 98, Loss: 0.0775, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 99, Loss: 0.0827, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 100, Loss: 0.1166, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 101, Loss: 0.1290, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 102, Loss: 0.1571, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 103, Loss: 0.2186, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 104, Loss: 0.1165, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 105, Loss: 0.1819, Train Acc: 1.0000, Val Acc: 0.7480\n",
      "Epoch: 106, Loss: 0.1267, Train Acc: 1.0000, Val Acc: 0.7480\n",
      "Epoch: 107, Loss: 0.1718, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 108, Loss: 0.1321, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 109, Loss: 0.1301, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 110, Loss: 0.1181, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 111, Loss: 0.1092, Train Acc: 1.0000, Val Acc: 0.7600\n",
      "Epoch: 112, Loss: 0.0795, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 113, Loss: 0.1262, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 114, Loss: 0.0890, Train Acc: 1.0000, Val Acc: 0.7600\n",
      "Epoch: 115, Loss: 0.1824, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 116, Loss: 0.0790, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 117, Loss: 0.0962, Train Acc: 1.0000, Val Acc: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  73%|███████▎  | 146/200 [00:00<00:00, 188.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118, Loss: 0.1008, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 119, Loss: 0.1190, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 120, Loss: 0.0962, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 121, Loss: 0.0729, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 122, Loss: 0.1364, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 123, Loss: 0.0653, Train Acc: 1.0000, Val Acc: 0.7640\n",
      "Epoch: 124, Loss: 0.1157, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 125, Loss: 0.1754, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 126, Loss: 0.1388, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 127, Loss: 0.0821, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 128, Loss: 0.0893, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 129, Loss: 0.0774, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 130, Loss: 0.0927, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 131, Loss: 0.0618, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 132, Loss: 0.1338, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 133, Loss: 0.1192, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 134, Loss: 0.0600, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 135, Loss: 0.0939, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 136, Loss: 0.0590, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 137, Loss: 0.1102, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 138, Loss: 0.1745, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 139, Loss: 0.1115, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 140, Loss: 0.0820, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 141, Loss: 0.0526, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 142, Loss: 0.0455, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 143, Loss: 0.0776, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 144, Loss: 0.1068, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 145, Loss: 0.1019, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 146, Loss: 0.1226, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 147, Loss: 0.0594, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 148, Loss: 0.1102, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 149, Loss: 0.1056, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 150, Loss: 0.1283, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 151, Loss: 0.0969, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 152, Loss: 0.0953, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 153, Loss: 0.0915, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 154, Loss: 0.0939, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 155, Loss: 0.1162, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 156, Loss: 0.1301, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 157, Loss: 0.1005, Train Acc: 1.0000, Val Acc: 0.7520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  92%|█████████▎| 185/200 [00:01<00:00, 189.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 158, Loss: 0.1217, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 159, Loss: 0.1449, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 160, Loss: 0.0738, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 161, Loss: 0.0718, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 162, Loss: 0.1437, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 163, Loss: 0.0576, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 164, Loss: 0.1202, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 165, Loss: 0.0652, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 166, Loss: 0.1605, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 167, Loss: 0.1145, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 168, Loss: 0.0880, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 169, Loss: 0.1450, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 170, Loss: 0.1157, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 171, Loss: 0.0883, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 172, Loss: 0.0718, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 173, Loss: 0.0974, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 174, Loss: 0.0970, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 175, Loss: 0.0592, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 176, Loss: 0.1602, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 177, Loss: 0.0784, Train Acc: 1.0000, Val Acc: 0.7580\n",
      "Epoch: 178, Loss: 0.1263, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 179, Loss: 0.0572, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 180, Loss: 0.1080, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 181, Loss: 0.1307, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 182, Loss: 0.0948, Train Acc: 1.0000, Val Acc: 0.7520\n",
      "Epoch: 183, Loss: 0.0538, Train Acc: 1.0000, Val Acc: 0.7480\n",
      "Epoch: 184, Loss: 0.0777, Train Acc: 1.0000, Val Acc: 0.7480\n",
      "Epoch: 185, Loss: 0.0968, Train Acc: 1.0000, Val Acc: 0.7440\n",
      "Epoch: 186, Loss: 0.1551, Train Acc: 1.0000, Val Acc: 0.7440\n",
      "Epoch: 187, Loss: 0.0949, Train Acc: 1.0000, Val Acc: 0.7440\n",
      "Epoch: 188, Loss: 0.0760, Train Acc: 1.0000, Val Acc: 0.7480\n",
      "Epoch: 189, Loss: 0.1118, Train Acc: 1.0000, Val Acc: 0.7460\n",
      "Epoch: 190, Loss: 0.1208, Train Acc: 1.0000, Val Acc: 0.7500\n",
      "Epoch: 191, Loss: 0.1040, Train Acc: 1.0000, Val Acc: 0.7540\n",
      "Epoch: 192, Loss: 0.0764, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 193, Loss: 0.0652, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 194, Loss: 0.1227, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 195, Loss: 0.0817, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 196, Loss: 0.0976, Train Acc: 1.0000, Val Acc: 0.7560\n",
      "Epoch: 197, Loss: 0.1050, Train Acc: 1.0000, Val Acc: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 200/200 [00:01<00:00, 181.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198, Loss: 0.0949, Train Acc: 1.0000, Val Acc: 0.7600\n",
      "Epoch: 199, Loss: 0.0970, Train Acc: 1.0000, Val Acc: 0.7620\n",
      "Epoch: 200, Loss: 0.0535, Train Acc: 1.0000, Val Acc: 0.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "cora_data_gpu = cora_data.to(device)\n",
    "# optimizer_gpu = optimizer.to(device)\n",
    "# loss_fun_gpu = loss_fun.to(device)\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "    loss = train(cora_model, cora_data, optimizer, loss_fn)\n",
    "    train_acc, val_acc = evaluate(cora_model, cora_data, cora_data.val_mask)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g1",
   "language": "python",
   "name": "g1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
