{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "408764d7-ca06-4613-8f8d-0a3e709b3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "56c00215-bb91-4b3b-82d1-10d8bbf9fe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ccfef061-754c-4f2e-b866-bb94e049aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6402b5f4-7950-4e52-bb38-5e39a04d4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_dataset = Planetoid('/tmp/cora', 'cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ce8ef461-23b2-4e9e-934e-bf58db9f9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_data = cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "70452dae-8617-4052-b4eb-a0cddefe1965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora has 2708 nodes\n",
      "cora has 10556 edges\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "num_nodes = cora_data.num_nodes\n",
    "print('cora has {} nodes'.format(num_nodes))\n",
    "\n",
    "num_edges = cora_data.num_edges\n",
    "print('cora has {} edges'.format(num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fb576725-b042-42b3-845d-8fe7d8f5dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data)\n",
    "print(cora_data.x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "869254d3-96e1-4b6d-8571-405bf118871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in cora train set, 140\n",
      "number of nodes in cora val set, 500\n",
      "number of nodes in cora test set, 1000\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "cora_x_train = cora_data.x[cora_data.train_mask]\n",
    "cora_x_val = cora_data.x[cora_data.val_mask]\n",
    "cora_x_test = cora_data.x[cora_data.test_mask]\n",
    "\n",
    "print(\"number of nodes in cora train set,\", cora_x_train.shape[0])\n",
    "print(\"number of nodes in cora val set,\", cora_x_val.shape[0])\n",
    "print(\"number of nodes in cora test set,\", cora_x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ea496a38-9639-4257-8bed-ff575ef9fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "torch.Size([2708])\n",
      "{0, 1, 2, 3, 4, 5, 6}\n",
      "[351. 217. 418. 818. 426. 298. 180.]\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data.y)\n",
    "print(cora_data.y.shape)\n",
    "s = set()\n",
    "histogram = np.zeros(7)\n",
    "for label in cora_data.y:\n",
    "    s.add(label.item())\n",
    "    histogram[label.item()]+=1\n",
    "print(s)\n",
    "print(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7f19a0de-496c-4467-9890-bbe189b15d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "1433\n",
      "2708\n",
      "1\n",
      "<class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data.x.shape)\n",
    "print(cora_data.x[170:180])\n",
    "print(cora_data.num_features)\n",
    "print(cora_data.num_nodes)\n",
    "print(cora_data.num_node_types)\n",
    "print(type(cora_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e11b8540-03ea-4238-bf4a-b6a384427d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    # hidden channels will be the embedding dimension for each attention head\n",
    "    # after applying the first GAT layer.\n",
    "    def __init__(self, in_channels, hidden_channels, \n",
    "                 num_heads, dropout_rate, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, \n",
    "                                dropout=dropout_rate)\n",
    "        self.conv2 = GATConv(hidden_channels*num_heads, num_classes, \n",
    "                                dropout=dropout_rate, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        out = self.conv1(out, edge_index)\n",
    "        assert out.shape[-1] == self.hidden_channels * self.num_heads\n",
    "        \n",
    "        out = F.elu(out)\n",
    "        out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        out = self.conv2(out, edge_index)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9002c7df-b429-4325-b334-6f9ae24c705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(pred[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8805834a-71ec-4e75-b4c0-e487266434ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data, test_mask, loss_fn):\n",
    "    accuracy_list = [0.0, 0.0]\n",
    "    loss_list = [0.0, 0.0]\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    \n",
    "    for i, mask in enumerate([data.train_mask, test_mask]):\n",
    "        accuracy_list[i] = pred[mask].eq(data.y[mask]).float().mean().item()\n",
    "        loss_list[i] = loss_fn(logits[mask], data.y[mask]).item()\n",
    "\n",
    "    return accuracy_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d37aedf9-6e12-40b1-b050-24c4c5d09e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(model):\n",
    "    num_params = 0\n",
    "    print(f\"Model Summary: {type(model).__name__}\\n\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.size())\n",
    "        num_params += param.numel()\n",
    "    print(f\"\\nTotal number of params: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8e7675f8-f805-4f47-aefa-e4839a266c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, optimizer, loss_fn, save_name, patience=100):\n",
    "    print(f\"Using {device}\\n\")\n",
    "    print(f\"model devide: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # Early stopping initialization\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Evaluate before training\n",
    "    acc_list, loss_list = evaluate(model, data, data.val_mask, loss_fn)\n",
    "    print(\"Before training: \")\n",
    "    print(f\"Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\\n\")\n",
    "    \n",
    "    # Start training\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "        loss = train(model, data, optimizer, loss_fn)\n",
    "        acc_list, loss_list = evaluate(model, data, \n",
    "                                       data.val_mask, loss_fn)\n",
    "    \n",
    "        # Update early stopping criteria\n",
    "        val_loss = loss_list[1]\n",
    "        val_acc = acc_list[1]\n",
    "        if val_loss < best_val_loss or val_acc > best_val_acc:\n",
    "            best_val_loss = min(best_val_loss, val_loss)\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), save_name)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "    \n",
    "        # Check if patience limit is reached\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "            \n",
    "        # Logging\n",
    "        if (epoch % log_freq == 0) or (epoch + 1 == num_epochs):\n",
    "            print(f\"Epoch: {epoch+1}, Loss: {loss:.4f}\")\n",
    "            print(f\"    Eval: Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\")\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        print(f\"model devide: {next(model.parameters()).device}\")\n",
    "        model.load_state_dict(best_model_state[\"state_dict\"])\n",
    "        print(f\"Model restored to the best state from epoch {best_epoch + 1}\")\n",
    "        print(f\"model devide: {next(model.parameters()).device}\")\n",
    "        \n",
    "    print(f\"\\nTraining completed.\\nBest Validation at Epoch: {best_epoch + 1}\\nBest Val Acc: {best_val_acc:.4f}, Best Val Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a96a7cb8-fef8-41b8-91c2-b08fd7892d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_heads = 8\n",
    "dropout_rate = 0.4\n",
    "emb_dim1 = 8\n",
    "lr = 0.005\n",
    "\n",
    "cora_num_classes = len(cora_data.y.unique())\n",
    "assert cora_num_classes == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "54be33f3-de21-4aee-908c-7894dfb144c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "log_freq = 50\n",
    "\n",
    "cora_model = GAT(cora_data.num_features, emb_dim1, num_heads, dropout_rate, \n",
    "            cora_num_classes).to(device)\n",
    "cora_data.to(device)\n",
    "\n",
    "lambda_l2 = 0.001\n",
    "optimizer = torch.optim.Adam(cora_model.parameters(), lr=lr, weight_decay=lambda_l2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cee20219-3752-4dc0-a600-d6cd7465298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "model devide: cuda:0\n",
      "Before training: \n",
      "Train Acc: 0.1214, Train Loss: 1.9582, Val Acc: 0.1840, Val Loss: 1.9537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|          | 11/1000 [00:00<00:09, 102.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.9646\n",
      "    Eval: Train Acc: 0.7000, Train Loss: 1.7718, Val Acc: 0.4500, Val Loss: 1.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   7%|▋         | 72/1000 [00:00<00:05, 155.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Loss: 0.1733\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0207, Val Acc: 0.7740, Val Loss: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 126/1000 [00:00<00:05, 168.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101, Loss: 0.1912\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0096, Val Acc: 0.7800, Val Loss: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  19%|█▊        | 187/1000 [00:01<00:04, 189.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151, Loss: 0.1388\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0073, Val Acc: 0.7660, Val Loss: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 205/1000 [00:01<00:04, 164.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201, Loss: 0.1056\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0068, Val Acc: 0.7560, Val Loss: 0.8198\n",
      "Early stopping triggered at epoch 206\n",
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 106\n",
      "Best Val Acc: 0.7880, Best Val Loss: 0.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(cora_model, cora_data, optimizer, loss_fn, \"cora_model_01.pth\", patience=100)\n",
    "cora_model.load_state_dict(torch.load(\"cora_model_01.pth\", map_location=device))\n",
    "cora_model = cora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "45ada998-66b5-4068-80c7-688dae9d2f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training: \n",
      "Train Acc: 1.0000, Train Loss: 0.0087, Val Acc: 0.7880, Val Loss: 0.7232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate after training\n",
    "acc_list, loss_list = evaluate(cora_model, cora_data, cora_data.val_mask, loss_fn)\n",
    "print(\"After training: \")\n",
    "print(f\"Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g1",
   "language": "python",
   "name": "g1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
