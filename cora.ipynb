{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "408764d7-ca06-4613-8f8d-0a3e709b3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "56c00215-bb91-4b3b-82d1-10d8bbf9fe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ccfef061-754c-4f2e-b866-bb94e049aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6402b5f4-7950-4e52-bb38-5e39a04d4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_dataset = Planetoid('/tmp/cora', 'cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ce8ef461-23b2-4e9e-934e-bf58db9f9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_data = cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "70452dae-8617-4052-b4eb-a0cddefe1965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora has 2708 nodes\n",
      "cora has 10556 edges\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "num_nodes = cora_data.num_nodes\n",
    "print('cora has {} nodes'.format(num_nodes))\n",
    "\n",
    "num_edges = cora_data.num_edges\n",
    "print('cora has {} edges'.format(num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fb576725-b042-42b3-845d-8fe7d8f5dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data)\n",
    "print(cora_data.x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "869254d3-96e1-4b6d-8571-405bf118871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in cora train set, 140\n",
      "number of nodes in cora val set, 500\n",
      "number of nodes in cora test set, 1000\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "cora_x_train = cora_data.x[cora_data.train_mask]\n",
    "cora_x_val = cora_data.x[cora_data.val_mask]\n",
    "cora_x_test = cora_data.x[cora_data.test_mask]\n",
    "\n",
    "print(\"number of nodes in cora train set,\", cora_x_train.shape[0])\n",
    "print(\"number of nodes in cora val set,\", cora_x_val.shape[0])\n",
    "print(\"number of nodes in cora test set,\", cora_x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ea496a38-9639-4257-8bed-ff575ef9fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "torch.Size([2708])\n",
      "{0, 1, 2, 3, 4, 5, 6}\n",
      "[351. 217. 418. 818. 426. 298. 180.]\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data.y)\n",
    "print(cora_data.y.shape)\n",
    "s = set()\n",
    "histogram = np.zeros(7)\n",
    "for label in cora_data.y:\n",
    "    s.add(label.item())\n",
    "    histogram[label.item()]+=1\n",
    "print(s)\n",
    "print(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7f19a0de-496c-4467-9890-bbe189b15d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "1433\n",
      "2708\n",
      "1\n",
      "<class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(cora_data.x.shape)\n",
    "print(cora_data.x[170:180])\n",
    "print(cora_data.num_features)\n",
    "print(cora_data.num_nodes)\n",
    "print(cora_data.num_node_types)\n",
    "print(type(cora_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e11b8540-03ea-4238-bf4a-b6a384427d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    # hidden channels will be the embedding dimension for each attention head\n",
    "    # after applying the first GAT layer.\n",
    "    def __init__(self, in_channels, hidden_channels, \n",
    "                 num_heads, dropout_rate, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, \n",
    "                                dropout=dropout_rate)\n",
    "        self.conv2 = GATConv(hidden_channels*num_heads, num_classes, \n",
    "                                dropout=dropout_rate, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        out = self.conv1(out, edge_index)\n",
    "        assert out.shape[-1] == self.hidden_channels * self.num_heads\n",
    "        \n",
    "        out = F.elu(out)\n",
    "        out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        out = self.conv2(out, edge_index)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9002c7df-b429-4325-b334-6f9ae24c705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(pred[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8805834a-71ec-4e75-b4c0-e487266434ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data, test_mask, loss_fn):\n",
    "    accuracy_list = [0.0, 0.0]\n",
    "    loss_list = [0.0, 0.0]\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    \n",
    "    for i, mask in enumerate([data.train_mask, test_mask]):\n",
    "        accuracy_list[i] = pred[mask].eq(data.y[mask]).float().mean().item()\n",
    "        loss_list[i] = loss_fn(logits[mask], data.y[mask]).item()\n",
    "\n",
    "    return accuracy_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d37aedf9-6e12-40b1-b050-24c4c5d09e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(model):\n",
    "    num_params = 0\n",
    "    print(f\"Model Summary: {type(model).__name__}\\n\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.size())\n",
    "        num_params += param.numel()\n",
    "    print(f\"\\nTotal number of params: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8e7675f8-f805-4f47-aefa-e4839a266c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, optimizer, loss_fn, save_name, num_epochs=1000, \n",
    "                log_freq=50, patience=100, logging=True):\n",
    "    print(f\"Using {device}, model: {next(model.parameters()).device}, data: {data.x.device}\")\n",
    "    \n",
    "    # Early stopping initialization\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Evaluate before training\n",
    "    if logging:\n",
    "        acc_list, loss_list = evaluate(model, data, data.val_mask, loss_fn)\n",
    "        print(\"Before training: \")\n",
    "        print(f\"Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\\n\")\n",
    "    \n",
    "    # Start training\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "        loss = train(model, data, optimizer, loss_fn)\n",
    "        acc_list, loss_list = evaluate(model, data, \n",
    "                                       data.val_mask, loss_fn)\n",
    "    \n",
    "        # Update early stopping criteria\n",
    "        val_loss = loss_list[1]\n",
    "        val_acc = acc_list[1]\n",
    "        if val_loss < best_val_loss or val_acc > best_val_acc:\n",
    "            best_val_loss = min(best_val_loss, val_loss)\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), save_name)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "    \n",
    "        # Check if patience limit is reached\n",
    "        if patience_counter >= patience:\n",
    "            if logging: print(f\"\\nEarly stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "            \n",
    "        # Logging\n",
    "        if logging and ((epoch % log_freq == 0) or (epoch + 1 == num_epochs)):\n",
    "            print(f\"Epoch: {epoch+1}, Loss: {loss:.4f}\")\n",
    "            print(f\"    Eval: Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\")\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state[\"state_dict\"])\n",
    "        \n",
    "    print(f\"\\nTraining completed.\\nBest Validation at Epoch: {best_epoch + 1}\\nBest Val Acc: {best_val_acc:.4f}, Best Val Loss: {best_val_loss:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a96a7cb8-fef8-41b8-91c2-b08fd7892d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_heads = 8\n",
    "dropout_rate = 0.4\n",
    "emb_dim1 = 8\n",
    "lr = 0.005\n",
    "\n",
    "cora_num_classes = len(cora_data.y.unique())\n",
    "assert cora_num_classes == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "54be33f3-de21-4aee-908c-7894dfb144c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "log_freq = 50\n",
    "\n",
    "cora_model = GAT(cora_data.num_features, emb_dim1, num_heads, dropout_rate, \n",
    "            cora_num_classes).to(device)\n",
    "cora_data.to(device)\n",
    "\n",
    "lambda_l2 = 0.001\n",
    "cora_optimizer = torch.optim.Adam(cora_model.parameters(), lr=lr, weight_decay=lambda_l2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "cee20219-3752-4dc0-a600-d6cd7465298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "model devide: cuda:0\n",
      "Before training: \n",
      "Train Acc: 0.1429, Train Loss: 1.9503, Val Acc: 0.1180, Val Loss: 1.9536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|          | 9/1000 [00:00<00:11, 86.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.9449\n",
      "    Eval: Train Acc: 0.6786, Train Loss: 1.7709, Val Acc: 0.5180, Val Loss: 1.8389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   8%|▊         | 81/1000 [00:00<00:06, 143.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Loss: 0.1804\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0240, Val Acc: 0.7820, Val Loss: 0.7323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 139/1000 [00:00<00:04, 173.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101, Loss: 0.1568\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0104, Val Acc: 0.7820, Val Loss: 0.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  18%|█▊        | 177/1000 [00:01<00:04, 182.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151, Loss: 0.1768\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0055, Val Acc: 0.7880, Val Loss: 0.7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  24%|██▎       | 237/1000 [00:01<00:03, 193.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201, Loss: 0.0734\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0048, Val Acc: 0.7840, Val Loss: 0.8094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  25%|██▌       | 251/1000 [00:01<00:04, 165.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251, Loss: 0.1309\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0040, Val Acc: 0.7780, Val Loss: 0.7363\n",
      "Early stopping triggered at epoch 252\n",
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 152\n",
      "Best Val Acc: 0.7940, Best Val Loss: 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(cora_model, cora_data, cora_optimizer, loss_fn, \"cora_model_01.pth\", num_epochs, log_freq, patience=100)\n",
    "cora_model.load_state_dict(torch.load(\"cora_model_01.pth\", map_location=device))\n",
    "cora_model = cora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "45ada998-66b5-4068-80c7-688dae9d2f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training: \n",
      "Train Acc: 1.0000, Train Loss: 0.0056, Val Acc: 0.7940, Val Loss: 0.7617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate after training\n",
    "acc_list, loss_list = evaluate(cora_model, cora_data, cora_data.val_mask, loss_fn)\n",
    "print(\"After training: \")\n",
    "print(f\"Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ab88e752-130c-4ec9-8b93-ee118d6cd533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cite_dataset = Planetoid('/tmp/Citeseer', 'Citeseer')\n",
    "cite_data = cite_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7b9b02e8-5a18-41ba-ae3b-01ddfa35037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3327\n",
      "Number of features per node: 3703\n",
      "Number of edges: 9104\n",
      "Number of undirectd edge: 4552\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "print(f\"Number of nodes: {cite_data.num_nodes}\")\n",
    "print(f\"Number of features per node: {cite_data.num_node_features}\")\n",
    "print(f\"Number of edges: {cite_data.num_edges}\")\n",
    "print(f\"Number of undirectd edge: {cite_data.edge_index.shape[1]//2}\")\n",
    "print(f\"Number of classes: {len(cite_data.y.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9f29fb34-1919-40a6-8858-310ce0142ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in cora train set, 120\n",
      "number of nodes in cora val set, 500\n",
      "number of nodes in cora test set, 1000\n"
     ]
    }
   ],
   "source": [
    "# For debug use only\n",
    "cite_x_train = cite_data.x[cite_data.train_mask]\n",
    "cite_x_val = cite_data.x[cite_data.val_mask]\n",
    "cite_x_test = cite_data.x[cite_data.test_mask]\n",
    "\n",
    "print(\"number of nodes in cora train set,\", cite_x_train.shape[0])\n",
    "print(\"number of nodes in cora val set,\", cite_x_val.shape[0])\n",
    "print(\"number of nodes in cora test set,\", cite_x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b2e551a2-bb96-43a7-9fee-6303b14261bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "model devide: cuda:0\n",
      "Before training: \n",
      "Train Acc: 0.1917, Train Loss: 1.7921, Val Acc: 0.1180, Val Loss: 1.8114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|          | 8/1000 [00:00<00:12, 79.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.7908\n",
      "    Eval: Train Acc: 0.8000, Train Loss: 1.5142, Val Acc: 0.5600, Val Loss: 1.6660\n",
      "Epoch: 11, Loss: 0.4038\n",
      "    Eval: Train Acc: 0.9833, Train Loss: 0.1888, Val Acc: 0.6940, Val Loss: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   5%|▌         | 52/1000 [00:00<00:06, 141.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.2961\n",
      "    Eval: Train Acc: 0.9917, Train Loss: 0.0526, Val Acc: 0.6780, Val Loss: 1.0169\n",
      "Epoch: 31, Loss: 0.2859\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0202, Val Acc: 0.6840, Val Loss: 1.0291\n",
      "Epoch: 41, Loss: 0.2409\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0129, Val Acc: 0.6860, Val Loss: 1.0434\n",
      "Epoch: 51, Loss: 0.2202\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0127, Val Acc: 0.6840, Val Loss: 1.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   9%|▊         | 86/1000 [00:00<00:05, 156.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, Loss: 0.2055\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0100, Val Acc: 0.6880, Val Loss: 1.0226\n",
      "Epoch: 71, Loss: 0.1150\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0114, Val Acc: 0.6840, Val Loss: 1.0360\n",
      "Epoch: 81, Loss: 0.2023\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0095, Val Acc: 0.6800, Val Loss: 1.0521\n",
      "Epoch: 91, Loss: 0.1560\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0133, Val Acc: 0.6900, Val Loss: 1.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 112/1000 [00:00<00:06, 145.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101, Loss: 0.2332\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0102, Val Acc: 0.6780, Val Loss: 1.0768\n",
      "Epoch: 111, Loss: 0.2458\n",
      "    Eval: Train Acc: 1.0000, Train Loss: 0.0060, Val Acc: 0.6820, Val Loss: 1.0402\n",
      "\n",
      "Early stopping triggered at epoch 113\n",
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 13\n",
      "Best Val Acc: 0.7060, Best Val Loss: 0.9822\n",
      "\n",
      "After training: \n",
      "Train Acc: 0.9750, Train Loss: 0.1345, Val Acc: 0.6820, Val Loss: 0.9822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cite_num_classes = len(cite_data.y.unique())\n",
    "assert cite_num_classes == 6\n",
    "\n",
    "cite_model = GAT(cite_data.num_features, emb_dim1, num_heads, dropout_rate, \n",
    "            cite_num_classes).to(device)\n",
    "cite_data.to(device)\n",
    "\n",
    "# Create optimizer for citeseer\n",
    "cite_optimizer = torch.optim.Adam(cite_model.parameters(), lr=lr, weight_decay=lambda_l2)\n",
    "\n",
    "# Train citeseer model\n",
    "train_model(cite_model, cite_data, cite_optimizer, loss_fn, \"cite_model_01.pth\", num_epochs=1000, log_freq=10, patience=100)\n",
    "cite_model.load_state_dict(torch.load(\"cite_model_01.pth\", map_location=device))\n",
    "cite_model = cite_model.to(device)\n",
    "\n",
    "# Evaluate after training\n",
    "acc_list, loss_list = evaluate(cite_model, cite_data, cite_data.val_mask, loss_fn)\n",
    "print(\"\\nAfter training: \")\n",
    "print(f\"Train Acc: {acc_list[0]:.4f}, Train Loss: {loss_list[0]:.4f}, Val Acc: {acc_list[1]:.4f}, Val Loss: {loss_list[1]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0c1c01cb-d47d-4df2-aecd-1a0b7af86361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_stats(models, data, val_mask, loss_fn):\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "\n",
    "    for model in models:\n",
    "        acc, loss = evaluate(model, data, val_mask, loss_fn)\n",
    "        accuracies.append(acc[1])\n",
    "        losses.append(loss[1])\n",
    "\n",
    "    # Convert to tensors\n",
    "    accuracies_tensor = torch.tensor(accuracies)\n",
    "    losses_tensor = torch.tensor(losses)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    avg_accuracy = torch.mean(accuracies_tensor).item()\n",
    "    std_accuracy = torch.std(accuracies_tensor).item()\n",
    "    avg_loss = torch.mean(losses_tensor).item()\n",
    "    std_loss = torch.std(losses_tensor).item()\n",
    "\n",
    "    return avg_accuracy, std_accuracy, avg_loss, std_loss, accuracies_tensor, losses_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c467d45a-d7ce-420b-b0cc-b5839f7c1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.7940, Std of Accuracy: 6.2829e-08, Average Loss: 0.7617, Std of Loss: 8.6604e-08\n",
      "tensor([0.7940, 0.7940, 0.7940, 0.7940, 0.7940, 0.7940, 0.7940, 0.7940, 0.7940,\n",
      "        0.7940])\n",
      "tensor([0.7617, 0.7617, 0.7617, 0.7617, 0.7617, 0.7617, 0.7617, 0.7617, 0.7617,\n",
      "        0.7617])\n"
     ]
    }
   ],
   "source": [
    "cora_val_stats = val_stats(cora_model, cora_data, cora_data.val_mask, \n",
    "                           loss_fn)\n",
    "avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor = cora_val_stats\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}, Std of Accuracy: {std_acc:.4e}, Average Loss: {avg_loss:.4f}, Std of Loss: {std_loss:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4832762c-93a0-4da0-81ae-4be8399cee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(Model_Class, num_runs, data):\n",
    "    models = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        print(f\"Run: {i+1}\")\n",
    "        # Create a new GAT model instance\n",
    "        model = Model_Class(data.num_features, emb_dim1, num_heads, dropout_rate, \n",
    "                    len(data.y.unique())).to(device)\n",
    "\n",
    "        # Create a new optimizer instance\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, \n",
    "                                     weight_decay=lambda_l2)\n",
    "\n",
    "        # Train the model\n",
    "        train_model(model, data, optimizer, loss_fn, \"temp_model.pth\", num_epochs, \n",
    "                    log_freq, patience=100, logging=False)\n",
    "        \n",
    "        # Load the best model state\n",
    "        model.load_state_dict(torch.load(\"temp_model.pth\", map_location=device))\n",
    "        \n",
    "        # Append the trained model to the list\n",
    "        models.append(model)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "55bafbb5-a7ee-4edf-a58b-916b983ffc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 130/1000 [00:00<00:05, 160.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 31\n",
      "Best Val Acc: 0.8080, Best Val Loss: 0.6696\n",
      "\n",
      "Run: 2\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 132/1000 [00:00<00:05, 165.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 33\n",
      "Best Val Acc: 0.8020, Best Val Loss: 0.6407\n",
      "\n",
      "Run: 3\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  19%|█▉        | 190/1000 [00:01<00:04, 162.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 91\n",
      "Best Val Acc: 0.8020, Best Val Loss: 0.6719\n",
      "\n",
      "Run: 4\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  15%|█▌        | 152/1000 [00:00<00:05, 166.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 53\n",
      "Best Val Acc: 0.8120, Best Val Loss: 0.6626\n",
      "\n",
      "Run: 5\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▎        | 125/1000 [00:00<00:05, 157.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 26\n",
      "Best Val Acc: 0.7880, Best Val Loss: 0.7368\n",
      "\n",
      "Run: 6\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  18%|█▊        | 176/1000 [00:01<00:05, 163.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 77\n",
      "Best Val Acc: 0.7900, Best Val Loss: 0.7064\n",
      "\n",
      "Run: 7\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 126/1000 [00:00<00:05, 167.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 27\n",
      "Best Val Acc: 0.7960, Best Val Loss: 0.7070\n",
      "\n",
      "Run: 8\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 129/1000 [00:00<00:05, 165.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 30\n",
      "Best Val Acc: 0.8060, Best Val Loss: 0.6850\n",
      "\n",
      "Run: 9\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 132/1000 [00:00<00:05, 162.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 33\n",
      "Best Val Acc: 0.7980, Best Val Loss: 0.6631\n",
      "\n",
      "Run: 10\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  18%|█▊        | 185/1000 [00:01<00:04, 171.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 86\n",
      "Best Val Acc: 0.7920, Best Val Loss: 0.6963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "cora_models = create_models(GAT, num_runs, cora_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0f036370-c8ad-480b-a7ca-43cf641d137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Runs: 10\n",
      "Average Accuracy: 0.7946, Std of Accuracy: 0.0105, Average Loss: 0.6888, Std of Loss: 0.0274\n"
     ]
    }
   ],
   "source": [
    "cora_val_stats = val_stats(cora_models, cora_data, cora_data.val_mask, \n",
    "                           loss_fn)\n",
    "avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor = cora_val_stats\n",
    "print(f\"Number of Runs: {len(acc_tensor)}\")\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}, Std of Accuracy: {std_acc:.4f}, Average Loss: {avg_loss:.4f}, Std of Loss: {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "9c3aa2f9-3783-4e64-a06c-dad7c22221b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 113/1000 [00:00<00:06, 146.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 14\n",
      "Best Val Acc: 0.7020, Best Val Loss: 0.9793\n",
      "\n",
      "Run: 2\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 114/1000 [00:00<00:05, 148.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 15\n",
      "Best Val Acc: 0.7040, Best Val Loss: 0.9581\n",
      "\n",
      "Run: 3\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 113/1000 [00:00<00:06, 145.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 14\n",
      "Best Val Acc: 0.7160, Best Val Loss: 0.9717\n",
      "\n",
      "Run: 4\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 115/1000 [00:00<00:05, 147.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 16\n",
      "Best Val Acc: 0.6920, Best Val Loss: 0.9679\n",
      "\n",
      "Run: 5\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 117/1000 [00:00<00:06, 146.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 18\n",
      "Best Val Acc: 0.7100, Best Val Loss: 0.9952\n",
      "\n",
      "Run: 6\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 112/1000 [00:00<00:05, 149.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 13\n",
      "Best Val Acc: 0.7160, Best Val Loss: 1.0164\n",
      "\n",
      "Run: 7\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  23%|██▎       | 227/1000 [00:01<00:05, 148.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 128\n",
      "Best Val Acc: 0.7080, Best Val Loss: 1.0113\n",
      "\n",
      "Run: 8\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 113/1000 [00:00<00:05, 148.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 14\n",
      "Best Val Acc: 0.7120, Best Val Loss: 0.9887\n",
      "\n",
      "Run: 9\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 115/1000 [00:00<00:06, 147.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 16\n",
      "Best Val Acc: 0.7100, Best Val Loss: 0.9545\n",
      "\n",
      "Run: 10\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|█▌        | 156/1000 [00:01<00:05, 152.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 57\n",
      "Best Val Acc: 0.7060, Best Val Loss: 1.0087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "cite_models = create_models(GAT, num_runs, cite_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b9b09f4e-33ef-4021-821b-64e2a2f7bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Runs: 10\n",
      "Average Accuracy: 0.6844, Std of Accuracy: 0.0147, Average Loss: 0.9899, Std of Loss: 0.0315\n"
     ]
    }
   ],
   "source": [
    "cite_val_stats = val_stats(cite_models, cite_data, cite_data.val_mask, \n",
    "                           loss_fn)\n",
    "avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor = cite_val_stats\n",
    "print(f\"Number of Runs: {len(acc_tensor)}\")\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}, Std of Accuracy: {std_acc:.4f}, Average Loss: {avg_loss:.4f}, Std of Loss: {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "b107f5e8-537c-48d1-9505-0a2dcd9a8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim1 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c7fb8584-3719-4b19-a617-d89318706de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT1(torch.nn.Module):\n",
    "    # hidden channels will be the embedding dimension for each attention head\n",
    "    # after applying the first GAT layer.\n",
    "    def __init__(self, in_channels, hidden_channels, \n",
    "                 num_heads, dropout_rate, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, \n",
    "                                dropout=dropout_rate)\n",
    "        self.conv2 = GATConv(hidden_channels*num_heads, hidden_channels, \n",
    "                             heads=num_heads, dropout=dropout_rate)\n",
    "        self.conv3 = GATConv(hidden_channels*num_heads, num_classes, \n",
    "                                dropout=dropout_rate, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv1(out, edge_index)\n",
    "        assert out.shape[-1] == self.hidden_channels * self.num_heads\n",
    "        out = F.elu(out)\n",
    "        \n",
    "        out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv2(out, edge_index)\n",
    "        assert out.shape[-1] == self.hidden_channels * self.num_heads\n",
    "        out = F.elu(out)\n",
    "\n",
    "        out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv3(out, edge_index)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "35551959-4886-496f-83a5-0dd9a383393c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 144/1000 [00:01<00:06, 131.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 45\n",
      "Best Val Acc: 0.8220, Best Val Loss: 0.6533\n",
      "\n",
      "Run: 2\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 114/1000 [00:00<00:06, 128.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 15\n",
      "Best Val Acc: 0.8020, Best Val Loss: 0.7172\n",
      "\n",
      "Run: 3\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 114/1000 [00:00<00:06, 132.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 15\n",
      "Best Val Acc: 0.8060, Best Val Loss: 0.6615\n",
      "\n",
      "Run: 4\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 116/1000 [00:00<00:06, 130.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 17\n",
      "Best Val Acc: 0.8060, Best Val Loss: 0.6557\n",
      "\n",
      "Run: 5\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 120/1000 [00:00<00:06, 128.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 21\n",
      "Best Val Acc: 0.8020, Best Val Loss: 0.6445\n",
      "\n",
      "Run: 6\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 116/1000 [00:00<00:06, 129.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 17\n",
      "Best Val Acc: 0.8140, Best Val Loss: 0.6530\n",
      "\n",
      "Run: 7\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  17%|█▋        | 171/1000 [00:01<00:06, 134.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 72\n",
      "Best Val Acc: 0.7920, Best Val Loss: 0.6648\n",
      "\n",
      "Run: 8\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 112/1000 [00:00<00:06, 133.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 13\n",
      "Best Val Acc: 0.8040, Best Val Loss: 0.7305\n",
      "\n",
      "Run: 9\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█▏        | 114/1000 [00:00<00:06, 132.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 15\n",
      "Best Val Acc: 0.7960, Best Val Loss: 0.7318\n",
      "\n",
      "Run: 10\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 120/1000 [00:00<00:06, 132.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 21\n",
      "Best Val Acc: 0.7820, Best Val Loss: 0.7960\n",
      "\n",
      "Number of Runs: 10\n",
      "Average Accuracy: 0.7976, Std of Accuracy: 0.0166, Average Loss: 0.7379, Std of Loss: 0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "cora_models = create_models(GAT1, num_runs, cora_data)\n",
    "\n",
    "cora_val_stats = val_stats(cora_models, cora_data, cora_data.val_mask, \n",
    "                           loss_fn)\n",
    "avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor = cora_val_stats\n",
    "print(f\"Number of Runs: {len(acc_tensor)}\")\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}, Std of Accuracy: {std_acc:.4f}, Average Loss: {avg_loss:.4f}, Std of Loss: {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "06033dfb-768c-427a-8eb3-c463f04af608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 109/1000 [00:00<00:07, 115.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 10\n",
      "Best Val Acc: 0.7080, Best Val Loss: 0.9618\n",
      "\n",
      "Run: 2\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 108/1000 [00:00<00:07, 117.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 9\n",
      "Best Val Acc: 0.6940, Best Val Loss: 0.9965\n",
      "\n",
      "Run: 3\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 110/1000 [00:00<00:07, 112.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 11\n",
      "Best Val Acc: 0.7040, Best Val Loss: 0.9433\n",
      "\n",
      "Run: 4\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 108/1000 [00:00<00:07, 119.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 9\n",
      "Best Val Acc: 0.6880, Best Val Loss: 1.0667\n",
      "\n",
      "Run: 5\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 109/1000 [00:00<00:07, 119.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 10\n",
      "Best Val Acc: 0.7020, Best Val Loss: 0.9361\n",
      "\n",
      "Run: 6\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 109/1000 [00:00<00:07, 118.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 10\n",
      "Best Val Acc: 0.7020, Best Val Loss: 0.9632\n",
      "\n",
      "Run: 7\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 108/1000 [00:00<00:07, 115.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 9\n",
      "Best Val Acc: 0.6900, Best Val Loss: 0.9720\n",
      "\n",
      "Run: 8\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 109/1000 [00:00<00:07, 117.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 10\n",
      "Best Val Acc: 0.7040, Best Val Loss: 0.9457\n",
      "\n",
      "Run: 9\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|█         | 111/1000 [00:00<00:07, 116.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 12\n",
      "Best Val Acc: 0.7060, Best Val Loss: 0.9286\n",
      "\n",
      "Run: 10\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|█▉        | 197/1000 [00:01<00:06, 119.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 98\n",
      "Best Val Acc: 0.6760, Best Val Loss: 1.0234\n",
      "\n",
      "Number of Runs: 10\n",
      "Average Accuracy: 0.6840, Std of Accuracy: 0.0130, Average Loss: 1.0145, Std of Loss: 0.1491\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "cite_models = create_models(GAT1, num_runs, cite_data)\n",
    "\n",
    "cite_val_stats = val_stats(cite_models, cite_data, cite_data.val_mask, \n",
    "                           loss_fn)\n",
    "avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor = cite_val_stats\n",
    "print(f\"Number of Runs: {len(acc_tensor)}\")\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}, Std of Accuracy: {std_acc:.4f}, Average Loss: {avg_loss:.4f}, Std of Loss: {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "56f360cc-bdb5-427a-850d-1e483e3d3b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: GAT1\n",
      "\n",
      "conv1.att_src torch.Size([1, 8, 8])\n",
      "conv1.att_dst torch.Size([1, 8, 8])\n",
      "conv1.bias torch.Size([64])\n",
      "conv1.lin_src.weight torch.Size([64, 1433])\n",
      "conv2.att_src torch.Size([1, 8, 8])\n",
      "conv2.att_dst torch.Size([1, 8, 8])\n",
      "conv2.bias torch.Size([64])\n",
      "conv2.lin_src.weight torch.Size([64, 64])\n",
      "conv3.att_src torch.Size([1, 1, 7])\n",
      "conv3.att_dst torch.Size([1, 1, 7])\n",
      "conv3.bias torch.Size([7])\n",
      "conv3.lin_src.weight torch.Size([7, 64])\n",
      "\n",
      "Total number of params: 96661\n",
      "\n",
      "Model Summary: GAT1\n",
      "\n",
      "conv1.att_src torch.Size([1, 8, 8])\n",
      "conv1.att_dst torch.Size([1, 8, 8])\n",
      "conv1.bias torch.Size([64])\n",
      "conv1.lin_src.weight torch.Size([64, 3703])\n",
      "conv2.att_src torch.Size([1, 8, 8])\n",
      "conv2.att_dst torch.Size([1, 8, 8])\n",
      "conv2.bias torch.Size([64])\n",
      "conv2.lin_src.weight torch.Size([64, 64])\n",
      "conv3.att_src torch.Size([1, 1, 6])\n",
      "conv3.att_dst torch.Size([1, 1, 6])\n",
      "conv3.bias torch.Size([6])\n",
      "conv3.lin_src.weight torch.Size([6, 64])\n",
      "\n",
      "Total number of params: 241874\n"
     ]
    }
   ],
   "source": [
    "summarize(cora_models[0])\n",
    "print()\n",
    "summarize(cite_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "5b2ccc17-3cfe-4b58-b0d7-0c6b8c25701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "\n",
    "# d_model = 64\n",
    "\n",
    "class GAT2(torch.nn.Module):\n",
    "    # hidden channels will be the embedding dimension for each attention head\n",
    "    # after applying the first GAT layer.\n",
    "    def __init__(self, in_channels, hidden_channels, \n",
    "                 num_heads, dropout_rate, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_heads = num_heads\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, \n",
    "                                dropout=dropout_rate)\n",
    "\n",
    "        self.encoder1 = TransformerEncoderLayer(\n",
    "            d_model=hidden_channels*num_heads, nhead=num_heads, dropout=0.2, \n",
    "            batch_first=True)\n",
    "    \n",
    "        self.conv2 = GATConv(hidden_channels*num_heads, num_classes, \n",
    "                                dropout=dropout_rate, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv1(out, edge_index)\n",
    "        assert out.shape[-1] == self.hidden_channels * self.num_heads\n",
    "        out = F.elu(out)\n",
    "\n",
    "        out = out.unsqueeze(0)\n",
    "        out = self.encoder1(out)\n",
    "        out = out.squeeze(0)\n",
    "        \n",
    "        out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv2(out, edge_index)\n",
    "        assert out.shape[-1] == self.num_classes\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "6f173012-9873-4bd8-a3c3-33fa8a7ae132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  17%|█▋        | 168/1000 [00:01<00:05, 142.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 69\n",
      "Best Val Acc: 0.7820, Best Val Loss: 0.7349\n",
      "\n",
      "Run: 2\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 130/1000 [00:00<00:06, 140.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 31\n",
      "Best Val Acc: 0.7980, Best Val Loss: 0.6882\n",
      "\n",
      "Run: 3\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  15%|█▍        | 147/1000 [00:01<00:06, 140.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 48\n",
      "Best Val Acc: 0.7860, Best Val Loss: 0.7375\n",
      "\n",
      "Run: 4\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 123/1000 [00:00<00:05, 146.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 24\n",
      "Best Val Acc: 0.7980, Best Val Loss: 0.6926\n",
      "\n",
      "Run: 5\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|█▋        | 164/1000 [00:01<00:06, 132.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 65\n",
      "Best Val Acc: 0.7840, Best Val Loss: 0.7504\n",
      "\n",
      "Run: 6\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 123/1000 [00:00<00:05, 147.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed.\n",
      "Best Validation at Epoch: 24\n",
      "Best Val Acc: 0.7920, Best Val Loss: 0.7026\n",
      "\n",
      "Run: 7\n",
      "Using cuda, model: cuda:0, data: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 132/1000 [00:01<00:07, 122.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[430], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m cora_models \u001b[38;5;241m=\u001b[39m create_models(GAT2, num_runs, cora_data)\n\u001b[1;32m      4\u001b[0m cora_val_stats \u001b[38;5;241m=\u001b[39m val_stats(cora_models, cora_data, cora_data\u001b[38;5;241m.\u001b[39mval_mask, \n\u001b[1;32m      5\u001b[0m                            loss_fn)\n\u001b[1;32m      6\u001b[0m avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor \u001b[38;5;241m=\u001b[39m cora_val_stats\n",
      "Cell \u001b[0;32mIn[334], line 15\u001b[0m, in \u001b[0;36mcreate_models\u001b[0;34m(Model_Class, num_runs, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, \n\u001b[1;32m     12\u001b[0m                              weight_decay\u001b[38;5;241m=\u001b[39mlambda_l2)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train_model(model, data, optimizer, loss_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_epochs, \n\u001b[1;32m     16\u001b[0m             log_freq, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, logging\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load the best model state\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice))\n",
      "Cell \u001b[0;32mIn[347], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data, optimizer, loss_fn, save_name, num_epochs, log_freq, patience, logging)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train(model, data, optimizer, loss_fn)\n\u001b[1;32m     21\u001b[0m     acc_list, loss_list \u001b[38;5;241m=\u001b[39m evaluate(model, data, \n\u001b[1;32m     22\u001b[0m                                    data\u001b[38;5;241m.\u001b[39mval_mask, loss_fn)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Update early stopping criteria\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[232], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred[data\u001b[38;5;241m.\u001b[39mtrain_mask], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[0;32m----> 8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "cora_models = create_models(GAT2, num_runs, cora_data)\n",
    "\n",
    "cora_val_stats = val_stats(cora_models, cora_data, cora_data.val_mask, \n",
    "                           loss_fn)\n",
    "avg_acc, std_acc, avg_loss, std_loss, acc_tensor, loss_tensor = cora_val_stats\n",
    "print(f\"Number of Runs: {len(acc_tensor)}\")\n",
    "print(f\"Average Accuracy: {avg_acc:.4f}, Std of Accuracy: {std_acc:.4f}, Average Loss: {avg_loss:.4f}, Std of Loss: {std_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g1",
   "language": "python",
   "name": "g1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
